{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c560d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0278869",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "def get_vocab():\n",
    "    with open('vocab.txt') as f:\n",
    "        for i, l in enumerate(f.read().splitlines()):\n",
    "            vocab[l] = i\n",
    "get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d946eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = dict()\n",
    "def word_id():\n",
    "    for word in vocab:\n",
    "        ix = vocab[word]\n",
    "        word2id[ix] = word\n",
    "word_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbcec47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9273"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40851d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {}\n",
    "def get_tags():\n",
    "    with open('tags.txt') as f:\n",
    "        for i, l in enumerate(f.read().splitlines()):\n",
    "            tag_map[l] = i\n",
    "get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8e8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2tag = dict()\n",
    "def id_tag():\n",
    "    for tag in tag_map:\n",
    "        ix = tag_map[tag]\n",
    "        id2tag[ix] = tag\n",
    "id_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e3d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-person': 0,\n",
       " 'B-experience': 1,\n",
       " 'O': 2,\n",
       " 'I-experience': 3,\n",
       " 'I-skill': 4,\n",
       " 'B-skill': 5,\n",
       " 'I-city': 6,\n",
       " 'B-city': 7,\n",
       " 'B-person': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebdc4dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b76a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []        \n",
    "train_labels = []\n",
    "train_file = 'train_resume.bie'\n",
    "with open(train_file) as f:\n",
    "    s = list()\n",
    "    t = list()\n",
    "    for line in f.read().splitlines():\n",
    "        #replace each token by its index if it is in vocab\n",
    "        #else use index of UNK\n",
    "        words = line.split()\n",
    "        if len(words) < 2:\n",
    "            train_sentences.append(s)\n",
    "            train_labels.append(t)\n",
    "            s = list()\n",
    "            t = list()\n",
    "        else:\n",
    "            word = words[0]\n",
    "            tag = words[-1]\n",
    "            if word in vocab:\n",
    "                s.append(vocab[word])\n",
    "            else:\n",
    "                s.append(vocab['UNK'])\n",
    "            if tag in tag_map:\n",
    "                t.append(tag_map[tag])\n",
    "            else:\n",
    "                t.append(tag_map['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7645e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        #maps each token to an embedding_dim vector\n",
    "        self.embedding = nn.Embedding(params['vocab_size'], params['embedding_dim'])\n",
    "\n",
    "        #the LSTM takens embedded sentence\n",
    "        self.lstm = nn.LSTM(params['embedding_dim'], params['lstm_hidden_dim'], batch_first=True)\n",
    "\n",
    "        #fc layer transforms the output to give the final output layer\n",
    "        self.fc = nn.Linear(params['lstm_hidden_dim'], params['number_of_tags'])\n",
    "    \n",
    "    def forward(self, s):\n",
    "        #apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "\n",
    "        #run the LSTM along the sentences of length batch_max_len\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
    "\n",
    "        #reshape the Variable so that each row contains one token\n",
    "        s = s.reshape(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
    "\n",
    "        #apply the fully connected layer and obtain the output for each token\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags\n",
    "    \n",
    "def loss_fn(outputs, labels):\n",
    "    #reshape labels to give a flat vector of length batch_size*seq_len\n",
    "    labels = labels.view(-1)  \n",
    "\n",
    "    #mask out 'PAD' tokens\n",
    "    mask = (labels >= 0).float()\n",
    "\n",
    "    #the number of tokens is the sum of elements in mask\n",
    "    num_tokens = int(torch.sum(mask).data.item())\n",
    "\n",
    "    #pick the values corresponding to labels and multiply by mask\n",
    "    outputs = outputs[range(outputs.shape[0]), labels]*mask\n",
    "\n",
    "    #cross entropy loss for all non 'PAD' tokens\n",
    "    return -torch.sum(outputs)/num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db499a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net({'vocab_size':len(vocab),'embedding_dim':200,'lstm_hidden_dim':100,'number_of_tags':len(tag_map)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56fc7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "def create_batch(train_data,train_labels,i,batch_size=32):\n",
    "    #compute length of longest sentence in batch\n",
    "    st = i*batch_size\n",
    "    en = st+batch_size\n",
    "    batch_sentences = train_data[st:en]\n",
    "    batch_tags = train_labels[st:en]\n",
    "    \n",
    "    batch_max_len = max([len(s) for s in batch_sentences])\n",
    "    \n",
    "    #prepare a numpy array with the data, initializing the data with 'PAD' \n",
    "    #and all labels with -1; initializing labels to -1 differentiates tokens \n",
    "    #with tags from 'PAD' tokens\n",
    "    batch_data = vocab['PAD']*np.ones((len(batch_sentences), batch_max_len))\n",
    "    batch_labels = -1*np.ones((len(batch_sentences), batch_max_len))\n",
    "\n",
    "    #copy the data to the numpy array\n",
    "    for j in range(len(batch_sentences)):\n",
    "        cur_len = len(batch_sentences[j])\n",
    "        batch_data[j][:cur_len] = batch_sentences[j]\n",
    "        batch_labels[j][:cur_len] = batch_tags[j]\n",
    "\n",
    "    #since all data are indices, we convert them to torch LongTensors\n",
    "    batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels)\n",
    "\n",
    "    #convert Tensors to Variables\n",
    "    batch_data, batch_labels = Variable(batch_data), Variable(batch_labels)\n",
    "    return batch_data,batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a19c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f1b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.2783, grad_fn=<DivBackward0>)\n",
      "1 tensor(2.2782, grad_fn=<DivBackward0>)\n",
      "2 tensor(2.2625, grad_fn=<DivBackward0>)\n",
      "3 tensor(2.2345, grad_fn=<DivBackward0>)\n",
      "4 tensor(2.1997, grad_fn=<DivBackward0>)\n",
      "5 tensor(2.1900, grad_fn=<DivBackward0>)\n",
      "6 tensor(2.1625, grad_fn=<DivBackward0>)\n",
      "7 tensor(2.1322, grad_fn=<DivBackward0>)\n",
      "8 tensor(2.0921, grad_fn=<DivBackward0>)\n",
      "9 tensor(2.0562, grad_fn=<DivBackward0>)\n",
      "10 tensor(1.9976, grad_fn=<DivBackward0>)\n",
      "11 tensor(1.9227, grad_fn=<DivBackward0>)\n",
      "12 tensor(1.8877, grad_fn=<DivBackward0>)\n",
      "13 tensor(1.8362, grad_fn=<DivBackward0>)\n",
      "14 tensor(1.8087, grad_fn=<DivBackward0>)\n",
      "15 tensor(1.7974, grad_fn=<DivBackward0>)\n",
      "16 tensor(1.7455, grad_fn=<DivBackward0>)\n",
      "17 tensor(1.8638, grad_fn=<DivBackward0>)\n",
      "18 tensor(1.8292, grad_fn=<DivBackward0>)\n",
      "19 tensor(1.7043, grad_fn=<DivBackward0>)\n",
      "20 tensor(1.5096, grad_fn=<DivBackward0>)\n",
      "21 tensor(1.4349, grad_fn=<DivBackward0>)\n",
      "22 tensor(1.4002, grad_fn=<DivBackward0>)\n",
      "23 tensor(1.3339, grad_fn=<DivBackward0>)\n",
      "24 tensor(1.3263, grad_fn=<DivBackward0>)\n",
      "25 tensor(1.2103, grad_fn=<DivBackward0>)\n",
      "26 tensor(1.1644, grad_fn=<DivBackward0>)\n",
      "27 tensor(1.2489, grad_fn=<DivBackward0>)\n",
      "28 tensor(1.1620, grad_fn=<DivBackward0>)\n",
      "29 tensor(1.1558, grad_fn=<DivBackward0>)\n",
      "30 tensor(1.7866, grad_fn=<DivBackward0>)\n",
      "31 tensor(0.9213, grad_fn=<DivBackward0>)\n",
      "32 tensor(1.1850, grad_fn=<DivBackward0>)\n",
      "33 tensor(1.0033, grad_fn=<DivBackward0>)\n",
      "34 tensor(1.0840, grad_fn=<DivBackward0>)\n",
      "35 tensor(1.3331, grad_fn=<DivBackward0>)\n",
      "36 tensor(0.8199, grad_fn=<DivBackward0>)\n",
      "37 tensor(0.9196, grad_fn=<DivBackward0>)\n",
      "38 tensor(0.6965, grad_fn=<DivBackward0>)\n",
      "39 tensor(0.6795, grad_fn=<DivBackward0>)\n",
      "40 tensor(1.0076, grad_fn=<DivBackward0>)\n",
      "41 tensor(1.5844, grad_fn=<DivBackward0>)\n",
      "42 tensor(1.3019, grad_fn=<DivBackward0>)\n",
      "43 tensor(0.9892, grad_fn=<DivBackward0>)\n",
      "44 tensor(1.2017, grad_fn=<DivBackward0>)\n",
      "45 tensor(0.9039, grad_fn=<DivBackward0>)\n",
      "46 tensor(0.9937, grad_fn=<DivBackward0>)\n",
      "47 tensor(1.1270, grad_fn=<DivBackward0>)\n",
      "48 tensor(0.8193, grad_fn=<DivBackward0>)\n",
      "49 tensor(0.7529, grad_fn=<DivBackward0>)\n",
      "50 tensor(1.5062, grad_fn=<DivBackward0>)\n",
      "51 tensor(0.9129, grad_fn=<DivBackward0>)\n",
      "52 tensor(0.8383, grad_fn=<DivBackward0>)\n",
      "53 tensor(0.6515, grad_fn=<DivBackward0>)\n",
      "54 tensor(0.6149, grad_fn=<DivBackward0>)\n",
      "55 tensor(0.7154, grad_fn=<DivBackward0>)\n",
      "56 tensor(0.6710, grad_fn=<DivBackward0>)\n",
      "57 tensor(0.7609, grad_fn=<DivBackward0>)\n",
      "58 tensor(0.4694, grad_fn=<DivBackward0>)\n",
      "59 tensor(0.7830, grad_fn=<DivBackward0>)\n",
      "60 tensor(1.0278, grad_fn=<DivBackward0>)\n",
      "61 tensor(1.0636, grad_fn=<DivBackward0>)\n",
      "62 tensor(1.3431, grad_fn=<DivBackward0>)\n",
      "63 tensor(0.8940, grad_fn=<DivBackward0>)\n",
      "64 tensor(1.0578, grad_fn=<DivBackward0>)\n",
      "65 tensor(0.9872, grad_fn=<DivBackward0>)\n",
      "66 tensor(1.0159, grad_fn=<DivBackward0>)\n",
      "67 tensor(0.9914, grad_fn=<DivBackward0>)\n",
      "68 tensor(0.8770, grad_fn=<DivBackward0>)\n",
      "69 tensor(0.7078, grad_fn=<DivBackward0>)\n",
      "70 tensor(0.5640, grad_fn=<DivBackward0>)\n",
      "71 tensor(0.8687, grad_fn=<DivBackward0>)\n",
      "72 tensor(0.5672, grad_fn=<DivBackward0>)\n",
      "73 tensor(0.7371, grad_fn=<DivBackward0>)\n",
      "74 tensor(0.5935, grad_fn=<DivBackward0>)\n",
      "75 tensor(0.6248, grad_fn=<DivBackward0>)\n",
      "76 tensor(0.7428, grad_fn=<DivBackward0>)\n",
      "77 tensor(0.8438, grad_fn=<DivBackward0>)\n",
      "78 tensor(0.8026, grad_fn=<DivBackward0>)\n",
      "79 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-161366b03bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# credit assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# update model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_data contains train_sentences and train_labels\n",
    "#params contains batch_size\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "num_epochs = 4\n",
    "batch_size = 32\n",
    "num_training_steps = (len(train_sentences)/batch_size)\n",
    "i = 0\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(math.ceil(num_training_steps)):\n",
    "        print(i,end=' ')\n",
    "        batch_sentences, batch_labels = create_batch(train_sentences,train_labels, i, 32)\n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # compute the model output\n",
    "        output_batch = model(batch_sentences)\n",
    "        # calculate loss\n",
    "        loss = loss_fn(output_batch,batch_labels)\n",
    "        # credit assignment\n",
    "        loss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        print(loss_fn(output_batch,batch_labels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63dfef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bdfc688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dab6186",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 992 into shape (992,9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e2e1ec240ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m992\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 992 into shape (992,9)"
     ]
    }
   ],
   "source": [
    "(np.argmax(output_batch.detach().numpy(),axis=1)==5).reshape(992,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7b46865",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = batch_sentences.detach().numpy()[(np.argmax(output_batch.detach().numpy(),axis=1)==5).reshape(14,29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0084fd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3311,    1, 4541, 7103, 8558, 4854, 9185, 8558, 1411, 1411,  332,\n",
       "       6321, 2558, 6710, 8399, 8799, 1411, 1760,    1, 6025, 1411,    1,\n",
       "          1, 3311, 7103,    1, 8652, 7495, 5294, 5294, 7495, 7495, 7495,\n",
       "       7495, 7540, 7540, 1848, 1848, 5494, 5494, 3311,  541, 4541, 3141,\n",
       "       7103, 1630, 8652, 4179, 6710, 6710,  219, 1848, 1162, 5443, 7038,\n",
       "        100])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e326c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java\n",
      "PAD\n",
      "jsp\n",
      "html\n",
      "struts\n",
      "logic\n",
      "tags\n",
      "struts\n",
      "sql\n",
      "sql\n",
      "stored\n",
      "procedures\n",
      "views\n",
      "oracle\n",
      "tools\n",
      "toad\n",
      "sql\n",
      "*\n",
      "PAD\n",
      "pl/sql\n",
      "sql\n",
      "PAD\n",
      "PAD\n",
      "java\n",
      "html\n",
      "PAD\n",
      "junit\n",
      "testing\n",
      "unit\n",
      "unit\n",
      "testing\n",
      "testing\n",
      "testing\n",
      "testing\n",
      "apache\n",
      "apache\n",
      "tomcat\n",
      "tomcat\n",
      "server\n",
      "server\n",
      "java\n",
      "servlets\n",
      "jsp\n",
      "jstl\n",
      "html\n",
      "javascript\n",
      "junit\n",
      "jdbc\n",
      "oracle\n",
      "oracle\n",
      "8i\n",
      "tomcat\n",
      "git\n",
      "eclipse\n",
      "log4j\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for t in tags:\n",
    "    print(word2id[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66380723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_sentences.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36dcb3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argmax(output_batch.detach().numpy(),axis=1)==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e64c51a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 29])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c987c6c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-200d245281bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "batch_sentences[(np.argmax(output_batch.detach().numpy(),axis=1)==5).reshape(14,29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "731506cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 29)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(output_batch.detach().numpy(),axis=1)==5).reshape(14,29).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09eb1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3311,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 1846, 7557,  399, 2109, 8843, 4541, 1054, 7103, 1054, 8558, 4854,\n",
       "         9185, 1916, 8558, 4013, 7836,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 3080, 4485, 7410, 1916, 5500, 4276, 7559, 1012, 4429, 8838, 7883,\n",
       "         3386, 1468,   15, 5699, 7187,   15, 8482,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 3080, 4485, 1067, 1411, 1411, 4129, 1054,  332, 6321, 1054, 1916,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 5495, 4276, 8093, 3167, 7674, 1074, 2558, 8843, 6710, 8399, 7674,\n",
       "         8799, 1054, 1916, 1411, 1760,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 3080, 4485, 8154,  332, 8675, 4485, 8843, 6025, 1411,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 7044, 1916, 2040, 7557, 5174, 8843, 3311, 1916, 7103,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025,   73, 4485, 8093, 5058, 4485, 7404, 1054, 8939,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 7636, 1162, 5638, 3497, 7557, 4263, 1167, 4276,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 7636, 8652, 5638, 7495, 7557, 6501, 6129, 2416, 4284, 1916, 4611,\n",
       "          821,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 5294, 5294, 7495, 7495, 1916,  827, 7495, 4276, 5820, 5923, 6443,\n",
       "         1916, 3080, 4485, 3668, 7495,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [9025, 7636, 7540, 7540, 1848, 1848, 8944, 6723, 5494, 5494, 1916, 7038,\n",
       "         5638, 6723, 3508, 1916, 2065,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1],\n",
       "        [6574, 3311, 1054,  541, 1054, 4541, 1054, 3141, 1054, 7103, 1054, 1630,\n",
       "         1054, 8652, 1054, 4179, 1054, 6710, 6710,  219, 1054, 1848, 1054, 1162,\n",
       "         1054, 5443, 1054, 7038,  100]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67e7aaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-skill'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ba07123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I-person',\n",
       " 1: 'B-experience',\n",
       " 2: 'O',\n",
       " 3: 'I-experience',\n",
       " 4: 'I-skill',\n",
       " 5: 'B-skill',\n",
       " 6: 'I-city',\n",
       " 7: 'B-city',\n",
       " 8: 'B-person'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3e4157d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-person': 0,\n",
       " 'B-experience': 1,\n",
       " 'O': 2,\n",
       " 'I-experience': 3,\n",
       " 'I-skill': 4,\n",
       " 'B-skill': 5,\n",
       " 'I-city': 6,\n",
       " 'B-city': 7,\n",
       " 'B-person': 8}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f1e8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a path\n",
    "PATH = \"../model/resume_ner_model.pt\"\n",
    "\n",
    "# Save\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e635f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(9273, 200)\n",
       "  (lstm): LSTM(200, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "# Load\n",
    "model = Net({'vocab_size':len(vocab),'embedding_dim':200,'lstm_hidden_dim':100,'number_of_tags':len(tag_map)})\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "471824a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = model(batch_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9815ac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f75773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = batch_sentences.detach().numpy()[(np.argmax(output_batch.detach().numpy(),axis=1)==5).reshape(14,29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "381c4915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3311,    1, 4541, 7103, 8558, 4854, 9185, 8558, 1411, 1411,  332,\n",
       "       6321, 2558, 6710, 8399, 8799, 1411, 1760,    1, 6025, 1411,    1,\n",
       "          1, 3311, 7103,    1, 8652, 7495, 5294, 5294, 7495, 7495, 7495,\n",
       "       7495, 7540, 7540, 1848, 1848, 5494, 5494, 3311,  541, 4541, 3141,\n",
       "       7103, 1630, 8652, 4179, 6710, 6710,  219, 1848, 1162, 5443, 7038,\n",
       "        100])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868788b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
